{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from util.dataset import DataSet\n",
    "from datetime import timedelta\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataSet(14, 0.9, '../data/letters/', validation=False)\n",
    "#pickle.dump(data, open('../data/letters/dataset.pkl', 'wb' ))\n",
    "#data = pickle.load(open('../data/letters/dataset.pkl', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i], cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(data.class_names[cls_true[i]])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(data.class_names[cls_true[i]], data.class_names[cls_pred[i]])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXtwVdW9x7+/BOQZCISXCREqoMijRsLLojwU7thyHa/c\njkrb0doRH8PMxdoHXlsLba3TwQ5Uq06ptB2raKsOvsrYKhVphStMoMhLhSJvJECTQEgIIWTdP5Js\n9/qtRc7ZyTk54ZzvZ4aZ/d1n/fZeOevsH3v/1m//lhhjQAghmU5WqjtACCHtATpDQggBnSEhhACg\nMySEEAB0hoQQAoDOkBBCANAZEkIIADpDQggBQGdICCEAgA5RGouIUTqmzcUXX9ysjoeNGzdGtgGA\nrCzb19fX18e0CfevoqIC1dXVsf/INEKPcSZgjMmoMc7NzTX5+fmBvuiii5w2R48etfSxY8cs7buW\n9L7s7GxLDxgwwLHp0aOHpX1vxO3Zs8fStbW1lvb5lPC1X1ZWhqqqqphjHMkZAkCHDp+b+Jyh/gLu\nueceSz/88MOOjT6O/kK0U4uXrl27WrqmpsbS586dc2zC/V26dGmLzktIeyY/Px/PPfdcoAcNGuS0\nefzxxy39zDPPWLqqqsqxqa6utnT37t0tPW/ePMdmxowZlj5z5ozT5o477rD0vn37LH3vvfc6NuFr\n/5e//KXzuQ8+JhNCCOgMCSEEQMTH5D59+mDWrFmBfuCBB5w2Om7Qq1evmMeNVTlnypQpMW18t9c6\n1hB+xAfcx2bAfsyPJyaabhQXF6OkpCTV3fCiY0UAcNttt0U+zltvvRVs+3436U5dXR3KysoCPWTI\nEKeNfuTt2LGjpTt37uzYnD171tInT5609PLlyx2bq6++2tKXXnqp0+aLX/yipQ8ePGjpTp06OTbh\nffFex7wzJIQQ0BkSQggAOkNCCAFAZ0gIIQAiTqDU1tZi7969gdZBVQDo1q2bpXNzc2MeV0+G6IDn\n22+/7djoyRDfJIzepyd3Nm3a5NiE/6YXXnjhPD1OX/75z39aibD33XdfTBudS+oLgicCX3LwihUr\nWnXMsWPHtso+HfB9r3PmzLH01q1bLf2Pf/zDsdHXrZ5k0Xm/QMOLDWHCEztN6HxFnah94MABx6Z/\n//7Bti+f2AfvDAkhBHSGhBACgM6QEEIARIwZduvWDV/60pcC7Uui7Nu3r6V13MD3fB/r3eTt27c7\nNvp9xcmTJzttdDKmPs+YMWMcm1OnTgXbvlhKulNfX4/KyspAL1q0KKZNPG0SsSRtJibBJ4twHK20\ntNT5PC8vz9Lhd5kB4KmnnnJsdDK0jscWFRU5Njr+F56TaEIXjfjss88srX0OYCfox/vb450hIYSA\nzpAQQgDQGRJCCICIMcP8/HwsWLAg0PE8i//sZz+z9COPPOK00fUKdV7QiBEjHBsd5/DlPOr+rVmz\nxtK/+93vHJsrrrgi2NYFLQlJB86dO2fVI/RdOzpefvz4cUv74u233HKLpcOxZ8B/Heu6iL4iIYcP\nH262bz5aEqPmnSEhhIDOkBBCANAZEkIIADpDQggB0IIFoaKiiyPU1dU5bfQEylVXXWVp38v4BQUF\nlvZVQdYTJI899pildSVsAFi4cKGzj5B0whiD06dPB1oXPQHcxGZ9Lb3zzjuOjS6oMG7cOEuHq+Q3\noZO7fSvo6UXm4lkgriUJ+rwzJIQQ0BkSQggAOkNCCAHQgphh1GRGHTP0dkLFLB588EFL++IIOka4\ncuVKp42O/+lCkjoWAdh/XyKKCxDS3sjJycF1110X6HAh1Ca2bNli6ddee83Su3btcmx0YWedQK0X\nfweA6dOnW1oXCgbcJOtnn33W0vn5+Y5NuLgDV8cjhJAI0BkSQgjoDAkhBEDEmOGmTZtirlR/9uxZ\nS//kJz9p9vPzHSeMb0GXQ4cOWVoXhADcQgs6Nuk7bjiHicVESTpSX19vFUiItaAS4F47w4YNc2z0\ncXJyciztK8Kg4/Zf+cpXnDbXXnutpU+cOGHpkSNHOjbhxdxY3JUQQiJAZ0gIIaAzJIQQAHSGhBAC\noAVJ1+FJBV/RBY1Ouva9ZB0rwOmz0dVvd+/e7bTRQV/f5I0mPKnCpGuSjpw8eRKrV68OdHFxsdNG\nX9tlZWWW1qte+vbpiY5wcYjztfFN5uikaz2holfYA+xrn0nXhBASATpDQggBnSEhhACIGDM0xniL\nqIbR8T2tWxKH89ls2LDB0mfOnHHaxIoR+go1hPcx6ZqkIx07dkS/fv0CXVhY6LTRMcM777zT0h99\n9JFjo69JnbitizYDbpGFQYMGOW369u1r6YMHD1q6T58+jg1XxyOEkBZCZ0gIIaAzJIQQAHSGhBAC\noJWr4/kSL3WS9bvvvmtp36TF17/+dUvroKqvWvakSZNi9mXixImWnjZtWszjTp48Odh+/vnnnc8J\nudCpq6tDeXl5oH3Vm7p27Wrp7373u5Y+efKkY7N27VpL6+tr6NChjo0+t6/qtp6sqampsbSv0nVL\nXp7gnSEhhIDOkBBCANAZEkIIgIgxQxFBx44dAx3PynfvvfeepX3VbidMmGBpHQPQBRcAN5k73K8m\npkyZYumHH3642b4CdqK1rtSbCeTn52Pu3LmBfuihh5w2b731lqX1GD/yyCNJ6du3v/1tZ9+SJUuS\ncq50pkuXLhg1alSge/fu7bTRhRl0G/05AIwePdrS+/fvt7TvGtUJ1eEK3E2Ei0oAbmGGoqIixyYc\n8/QVevHBO0NCCAGdISGEAKAzJIQQAC0o1BAufuArZBCrMIOv0MPvf/97Sx85csTSt956q2OjX/q+\n4YYbnDaxCi2wEINLbW0t9uzZ02ybL3/5y83qZLF48eK49sVi4MCBwfbRo0db1acLkU6dOmHw4MGB\n9hVd1XmG8Xyui6XomLvODwTcVS4/+eQTp82pU6csrYs56M8BuyAsi7sSQkgE6AwJIQR0hoQQAoDO\nkBBCAAASpSJsQUGBueeee5ptE08ittMJFeDU2pesqV/wjlV0AXCTsGMFVseOHYuSkpKMmmURkQt6\nSUAdtPetnPbZZ58F2/X19TDGZNQY5+fnmzlz5gTaN6mpV6Tr2bOnpX2V5fXLEbqNr0hLaWmppfPy\n8pw2ep9eGdNnc9NNN1nbW7dujTnGvDMkhBDQGRJCCAA6Q0IIARAxZigixwDsS1532h2DjDF9YzdL\nHzjG6Q/H2E8kZ0gIIekKH5MJIQR0hoQQAqCVC0LFQkTyAPytUQ4AcA7AsUY93hjjJji1/pwjALwQ\n2jUEwP8aY55M9LnI56RorDsAOG6MyU30scnnpHBszwDY2rjrHIC5xpgPEn2u4JxtFTMUkYUAThlj\nfqH2S2M/omdrxz5nRwCHAIwxxhxM9PGJn7YaazrDtidVYysiMwE8YIy5PhHH95GSx2QRGSoiO0Rk\nOYDtAApFpCL0+W0isqxxu7+IrBCREhHZICITz3dcDzMAfERHmDracKxJG9PGY9sDQHnMVq0gqY/J\nMRgO4HZjTEnj/wLn4wkAi4wxH4jIYAB/BjBKRCYAuNMYc28ztrcBeDFRHSYtpi3GmqSGZI5tjohs\nBtAZDY/n0zxtEkYqneFuY4y7OpTLdACXh94j7iUiXYwx6wGsP5+RiHQGMBPAA63uKWktSR1rklKS\nObaVxpgiABCRawD8AcDo87RtNal0huFlsOoBhF+k7hzaFrQsSDsTwHpjzPEW9o8kjmSPNUkdbTK2\nxpj3RSRfRHobY9yl+RJAu0itaQy6lovIMBHJAnBz6ONVAIK1K0XEXRfQz2zwEbndkaSxJu2AZI6t\niIxEg7NNWtywXTjDRuYD+CuAdQDCEx5zAUwSkS0isgPAHAAQkQki8mvfgUQkBw3xhdeS22XSQhI2\n1qTdkcixzRGRzY1xw+VoiE0mLf2Fr+MRQgja150hIYSkDDpDQggBnSEhhACgMySEEAB0hoQQAiBi\n0nXv3r3NwIEDm22jV6nTK2b5VshqyYy2Xh2voqLCaaP3derUydJ6BTDA7n9FRQWqq6szauW0rKws\nk5X1+f+Rvu9IM2LEiFafd8uWLc6+s2fPtvq48ZBpq+Nd6Csgap9y2WWXNdv+8OHDKC8vjznGkZzh\nwIEDsXLlykD7luc8ffq0pfv2tatt66UcAdex1dXV2Z3s4HbzxIkTln7tNTel8I033rD0pZdeaunC\nwkLHpqamJtheunSp83m6k5WVZY3RJZdcEtOmpCSet7Gax3eeAwcOtPq4JP3o3bu3pV98sfl3K2bP\nnh3XcfmYTAghiHhneODAAcybNy/Qe/bscdroBd9zc+1Scz/+8Y8dm+Li4uY76bkzPHLkiKVXrFjh\ntFm3bp2lV69ebWnfQtg/+tGPmu1LulNUVJSQO72o7N+/v0V2ixYtsvT8+fMT0Z20pri4OPIYv/fe\ne5aeNi2pBWQs9HU7derUSPZdunSJqx3vDAkhBHSGhBACgM6QEEIA0BkSQgiAiBMoNTU12LVrV6A/\n+eQTp03nzp0t3bNnT0tv27bNsRk+fLilu3fvbmk9KQO4aT3dunVz2uicRp3C4zsuq/i0nli5qD5m\nzZrl7HviiSdi2n3/+9+39P3332/p/v37Oza+nFTSPHrS4nvf+57T5rHHHmv1ee66666Y504WvDMk\nhBDQGRJCCAA6Q0IIARAxZpidnW29qqVjcID9OhsA5OXlWdqX6Kxje6EVtAC4r+cB7utbo0e7i2at\nXbu22XOH38E937kzjT179uAb3/hGoJ9//vmYNjqR/tChQ5HP+6tf/SrmvvXr3UXUxo8fb2n9LnV5\nubtkRqaP8Y4dO3DllVcG+sMPP4x8DJ3sDrjjpX1BWxL++8LzHM3BO0NCCAGdISGEAKAzJIQQABFj\nhsYYK37nK+HVtWtXS+tcPl/RBV1nUMfyfLEHX46gxhcTDOOLRTLPkKQ7p0+ftupH+mKoBw8etHRB\nQUFcxw0zY8YMS69atcqxue+++yz99NNPxzyPxhe/9NXHjAXvDAkhBHSGhBACgM6QEEIA0BkSQgiA\niBMoImJNSvgCr1VVVZaurKy0tG/Swpe8HSae5Gg9ceNro8/DpGuXsrIyLF++PNDxJF0/9NBDll64\ncGFC+qID8roISDzo9TJIfOhiG3oSU096+njnnXcS2qcmdFJ/oqqb886QEEJAZ0gIIQDoDAkhBEDE\nmGFWVhZ69OgRaF98TcfhdJK1L4Fa79M2vsKtOv7nW+xcH1fHK31rODPpOjo6AT6V36F+KV/HsEnL\n0GuMv/DCC06b6dOnt0lfWlI8OB54Z0gIIaAzJIQQAHSGhBACoAUxw/Dq9L6iCzpepON2vtw+nT+m\n25w9e9ax0bEgX/6iPk48x830PMNkcccdd1ha559OmTLFsZk3b17k8wwbNszSvmLC4XNt2rQp8jky\nkWPHjllaF2EAgOrqakuHfUVrmDZtWkKOEwveGRJCCOgMCSEEAJ0hIYQAoDMkhBAArSzU4JuAiFXZ\n2jeBooPc+hi+SQ19XF8bnYitz+2r1M2k6+jo1fFaUqjh1Vdfdfbdf//9Me1qa2stHU8F9DVr1gTb\nY8eOjaN3JB50sZQL7VrinSEhhIDOkBBCANAZEkIIgIgxw5ycHCsB0hf/0zEcHTfo2bOnY6Nje9nZ\n2Zb2FX/VMUJfrEjb6eP64ozhNkzAjo8xY8ak7NyPPvqopRcsWJCinhDNrFmzLL1ixYoU9SQ+eGdI\nCCGgMySEEAB0hoQQAoDOkBBCAEScQMnLy8M3v/nNQN98881OGz2poicxunfv7tjESo7WkzKAuzpX\nbm6u00Ync+sqGr4qyOFE7AstaTRV3HjjjanuAiGthneGhBACOkNCCAFAZ0gIIQAixgzr6+utCsUf\nf/yx00bH2XQ80LeKnY4rxpPsrF8K91W6jlVl25c0TlqPr3p0cXGxpeOJxxYUFFj6zTffdNpcddVV\nEXtHLjRWr15t6WS9DEFvQAghoDMkhBAAdIaEEAIgYswwOzsbvXr1CvTUqVOdNr6iCmF8z/s6H1Br\nX2xPxwP1CnuAm4t46tQpS/viVswtbD2+OJ6vkG6qYAEO4oN3hoQQAjpDQggBQGdICCEA6AwJIQRA\nxAmU0tJSLF68ONAtmWyIJ3itg+2+CRR9bl+A/jvf+U6zNr7+hyt5//GPf4zZV9J2fO1rX3P2bd++\n3dJbtmxpq+6QNIN3hoQQAjpDQggBQGdICCEAAIkS9xORYwD2Ja877Y5Bxpi+qe5EW8IxTn84xn4i\nOUNCCElX+JhMCCGgMySEEAB0hoQQAiDJzlBE8kRkc+O/IyJyKKTdkteJO++zInJMRDYn6xykgVSM\nsYh0EJFzofNsFJGJyTgXafsxlgb+T0RmhPbNFpGViT6Xdd62mkARkYUAThljfqH2S2M/ElbjSUSm\nADgN4DfGmKJEHZc0T1uNsYh0AHDcGJPbqGcCeMAYc30ijk/OTxuOcRGA5QCuAtAJwD8BzDDG7EnE\n8X2k5DFZRIaKyA4RWQ5gO4BCEakIfX6biCxr3O4vIitEpERENsRzB2CMWQOgLGl/AIlJssdY0QNA\neeJ6T+IhmWNsjNkM4K8AvgfgxwB+m0xHCER8NznBDAdwuzGmpPF/+vPxBIBFxpgPRGQwgD8DGCUi\nEwDcaYy5N/ldJS0kmWOc0xgG6QxgAIBpnjYk+SRzjBcA2IiGp7yxie22Syqd4W5jTEkc7aYDuDxU\n4KGXiHQxxqwHsD5pvSOJIJljXNkUAhGRawD8AcDo1naYRCZpY2yMqRSRV9AQEjmbmO6en1Q6w6rQ\ndj2AcDmbcA1/ATDeGFPbJr0iiaRNxtgY876I5ItIb2MMwyNtS7LHuL7xX9JpF6k1jUHXchEZJiJZ\nAG4OfbwKwNwm0RhYJRcYyRxjERmJhguGccMUcqFfx+3CGTYyHw0B03UADob2zwUwSUS2iMgOAHMA\nQEQmiMivfQcSkZcB/APACBE5KCLfTGrPSbwkbIzRGDNsjBsuR0Pciu+Wpp5EjnGbwneTCSEE7evO\nkBBCUgadISGEgM6QEEIA0BkSQgiAiHmGffr0MYMHDw60b/JFr1KXnZ0duVM1NTWW3r17t9OmttZO\nV/L1Ra+q17NnT0sPGjTIsSktLQ22KyoqUFVVFXs5vzQiLy/PFBYWBto3fmfP2vmvHTrYP6O6ujrH\npmPHjs2eVx8TAKqrqy197tw5p01OTk6zfdG/EwAoL/88AycTx7hbt24mNze32Tb6etLXkm81St1G\nj7keKwC46CK7zkM8x41n9czDhw8H2xUVFaiuro45xpGc4eDBg1FS8nmyue9HX1lZaWntgHwd1+zY\nscPSt956q9Nm//79lvb96Lt27WrpmTNnWnrp0qWOzZIlS4Ltp556KmZf043CwkK8++67gfb9gI8c\nOWLp3r17W/rf//63YzNgwABL6x/00aNHHZuNGzda+sSJE06b66+3azPk5eVZ+sCBA47Nn/70p2Db\n9xtId3JzczF3bpDy53VA+j+nLl26WPrMmTOOjb7e+va1K+1PnTrVsQnfXAFAVVWV06Zbt26WPnXq\nVLOfA8CCBQuC7WXLljmf++BjMiGEgM6QEEIARHxMrq6uth6TP/74Y6fNv/71L0vrW+MJEyY4Njpu\noGOGe/fujWmjY0WAe2v/wQcfWNr32JXpdOjQAb169Qq0L5bXvXt3S+vQh+/RWj/+6Fhk6AX+gIkT\n7SpPejwB99FMP0Jdcskljo3vXJlEZWUlVq1a1Wwb/eisvzNfiEyP+5AhQ5o9BgC8//77ll67dq3T\nRscer7jiCkvPmDEDmrBNvOPNO0NCCAGdISGEAKAzJIQQAHSGhBACIOIEyq5du3DjjTcG2pcbprn8\n8sst7Uvi1QmeegLFl5tYUVFh6f79+zttwn0FgJ07d1pa58sBdr5iJlb0qa2txb59+wLt+14PHTpk\n6U6dOlnaNzGlfys6qO1LgNc5aPp3AbhjqNv06dPHsQn3NxMnU7p06YIrr7wy0Hv2uEuL6DHUk2a+\na19PdK5bt87S69e7Ba379etn6U2bNjltdN6qnjz94Q9/6NiE8yB9eZQ+eGdICCGgMySEEAB0hoQQ\nAiBizDA/Px/z588PtC/+p5Ofi4uLLe17p1E/0+vkzYsvvtixCce1fMcA3CRdHUMMv8zdRPhvysR4\nUmlpKRYvXhzokydPOm10XE5rnXgPuEUW9DvrV199tWNz77326pG+4gI65qTPo4s9APbvIp535dON\nrKws6zu4/fbbnTbhYh2A+937vjcd73v66act/fe//92xifXCBQD84Ac/sPQXvvAFSw8dOtSxCV/H\nr7zyivO5j8z7JRBCiAc6Q0IIAZ0hIYQAiF7cFd/61rcC7Yup+QomhPG94K3jPDqOkJ+f79jo3CNf\nDb3NmzdbWr/gresm6nNnYsywrKwML7/8cqB9OYM6pqvjcrpYAuDWnNN1L7ds2eLYhAvtAkDnzp2d\nNvq4OudRa9IQ/7v55s+XNNa1Jn3oPENfoV1dWCNcFxMA1qxZ49joXFJ9HgC4++67La39gc/nhAuM\n+Ood+uCdISGEgM6QEEIA0BkSQggAOkNCCAEQcQIFsIOVvgkGXRlZV6n1JWvq4xQUFFj6q1/9asx+\nbdu2zdn30UcfWfrNN9+09Lhx4xybWBNAmYaezALcRGydKOub6NC/Ax2AP3jwoGOjfysDBw502ugJ\nOZ18rydqfG0yjYsuusi6xnTRE8Bd5Ov06dOW9iXA6+9aFzrxFc3QL1SMHj3aaaN/X/rFDd9kTiw/\n5YN3hoQQAjpDQggBQGdICCEAIsYMq6qqsGHDhkD7Yi89evSwtH6J2hcz1PEIHafSxR4Ad9F4X3GA\n4cOHW1oXbvAVgAgn6eo4VybQuXNnqyDvp59+6rTRMUMdG/IlOuvfio4D+b5rHfMNFyRtYuvWrZbW\nRUd9CbeZnlgP2H+3LxarC77qlxp8hY9jfZe+sRg5cqSlfcWE9ZjqpP4xY8Y4NuHfra84jA/eGRJC\nCOgMCSEEAJ0hIYQAiBgz3LlzJ66//vpm20yYMMHSjz76qKV9cR/9TK/zlfLy8hwbnbOk8xsB4Mkn\nn7T0sGHDLF1VVeXYdO3aNdh+/PHHnc/TnaFDh+L1118P9IIFC5w2L730kqX1+PkKdOp4ki4MrOPG\nvuP6YtSzZ8+2tI4v+fry05/+NNj2FQ5Jd7KysqxcUN+1o4tx6DiwLrAAuHHfXr16WTo839BEeXm5\npadMmeK0efDBBy193XXXWXrIkCGOzTPPPBNsHz9+3PncB+8MCSEEdIaEEAKAzpAQQgDQGRJCCIAW\nFGoIoxOfATc5U1eT1itbAW6itn5pv6yszLHRVXR9+AoGhPEVZcjUJNwm6urqrIDz2LFjnTZvvPGG\npfXEhm/VRL0ang5q+yZQdu7caWnf2Ojfjk4I941xeDIgE8e7vr7eqk7uW0FQT4boyUbfGOvvUk+A\n6URuwF2xctCgQU4b/XLENddcY+nwpGcT4QmgeFdA5J0hIYSAzpAQQgDQGRJCCICIMUMRsWIJvqKK\nOt63bt06S+sXswF3Ray//OUvln711VcdGx0b0ivfAW4sQcc4ffGiTC/8qcd4/PjxTpuioiJL6xX0\nfC/k67iNTsj1Jf7u3bvX0r7Yll7ZbdeuXZbWxTkA/+82k8jOzraKt/pibvo7ineFuTB6TH2J2n37\n9rW0jgED7rXdr18/S/vil+HfSrzXNO8MCSEEdIaEEAKAzpAQQgDQGRJCCIAWTKCEA+G+oLdGB7Rf\neeUVp42eDNGVbJcvX+7tSxhf4PXQoUOW/s1vfmNpX3XlcEKuroCSCWRlZVnBcj25BbiTKqtXr7a0\nrxqQTsDVQW/fZJYeP60BYNmyZc2e2/cb1RN0mUZ9fb31PfmuHT1Zpcfr2LFjjs2HH35o6fXr11v6\npptucmx0lWpf1e0ZM2ZYWk/EaH8B2OPuq8rtg3eGhBACOkNCCAFAZ0gIIQAixgzr6+ut2I8vnlRR\nUWFpvXqZL9agbSZPnmzpwsJCx0YnUOsV9QBg27ZtltaJvvq8gB3bysTk3OzsbKuogq9Ihv7udXzJ\nl8QbK2boi+3pWI+vMIiuyKwLM/gScsPjGm88KZ0QEet68RUy0EnW+lrwrWI3btw4S+vr2Ldqov7+\nfQU7Ro0aZWl9rfuSqsNJ5b5iHT54Z0gIIaAzJIQQAHSGhBACoAXFXcPP575Yg87du/baay192WWX\nOTb6OJMmTbK0L3anYw2+uEFBQUGzffPFk8I5c5lY+LOmpgbbt28PdH5+vtNm5syZlta5fTpvFHBz\n2XT8yBcr0vjGQ8cMdazLF6cKxx4zMWao8V0H+nrS8VrfNalXsdQrE/pWItTXvo4tA+5vR9v4/FD4\nOMwzJISQCNAZEkII6AwJIQQAnSEhhACIOIEyYMAA3H333YH2JTrrwKtuo4OqgBsY1wF433l0YNwX\nJF25cqWldQKxL/AanvBpSXXfC52Kigrre/MF1/W+3NxcS/sqGusEdz3mvqIZmrVr1zr7Vq1aZWkd\nxPe9xD916tRg+8UXX4x53nTjyJEj+PnPfx5oXzVwPZGhE+t9K0/qZHtt4zuPJp5JS31dlpaWOm1u\nuOGGYNtX6MUH7wwJIQR0hoQQAoDOkBBCAAASJelURI4B2Je87rQ7Bhlj+sZulj5wjNMfjrGfSM6Q\nEELSFT4mE0II6AwJIQRACwo1REFE8gD8rVEOAHAOQFN11/HGGLdaZ+vP2QHAcWNMbmjfXQBGGWPu\nT/T5MplUjG/jeQsBPAXgCjT8h/46gPnGmNgrlJHIpHCcvwJgCYBsAEuNMY8l4zzB+doqZigiCwGc\nMsb8Qu2Xxn64ZWdadh46wxTQhuMrADYCWGKMea5xvH8L4LAx5n8TcQ5yftpwnDsC+ATANABHAJQA\n+G9jzM5EHN9HSh6TRWSoiOwQkeUAtgMoFJGK0Oe3iciyxu3+IrJCREpEZIOITExFn0n8JHl8/wNA\nhTHmOQAwxtQBmAfgbhFxX4sgSSPJ4zwRwEfGmH3GmDMAXgLgrjWaQFIZMxyOhv/dRwBwF8T9nCcA\nLDLGjAW1iZYSAAABc0lEQVRwC4CmL3eCiPz6PDY5IrK56R+AHyWy4yQukjW+I9FwZxhgjKkAcBjA\npYnoOIlEssa5AMCBkD7YuC9pJDVmGIPdxpiSONpNB3B56J3FXiLSxRizHsD689hUGmOKmkTTY3Kr\nekuikszxJe2HtBnnVDrDcHnkegDhN7TDjzuCJAZpSdJI1vjuAPCf4R0ikouGu4ZPW9BP0jqSNc6H\nAISXxRyI5u88W027SK1pDLqWi8gwEckCcHPo41UA5jYJESnS9qR9k+DxfRsNdxVfb2zfAcBiAM8Y\nY9ySSKTNSPA4fwBghIgMEpFOaHi0fiPRfQ7TLpxhI/MB/BXAOjTEB5qYC2CSiGwRkR0A5gAxY4ak\n/ZGQ8W284P4LwGwR2YWGGcdKAA8nuf8kPhI1zmcB/A+Ad9DwNPC8MeaTZHacr+MRQgja150hIYSk\nDDpDQggBnSEhhACgMySEEAB0hoQQAoDOkBBCANAZEkIIADpDQggBAPw/Ej4rDPoXWskAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f231cec10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(data.x_train[:9], data.y_train_cls[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, data.img_size_flat], name='x')\n",
    "y_true = tf.placeholder(tf.float32, [None, data.num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = lambda shape: tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "new_biases = lambda length: tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "    \n",
    "def new_fc_layer(inp, num_inputs, num_outputs, use_relu=True, keep_prob=0):\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    layer = inp\n",
    "    \n",
    "    if keep_prob:\n",
    "        layer = tf.nn.dropout(inp, keep_prob) * keep_prob\n",
    "\n",
    "    layer = tf.matmul(inp, weights) + biases\n",
    "\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 40) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2 = new_fc_layer(inp=x, num_inputs=data.img_size_flat, num_outputs=fc2_size, use_relu=True, keep_prob=0.3)\n",
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 36) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc3 = new_fc_layer(inp=layer_fc2, num_inputs=fc2_size, num_outputs=data.num_classes)\n",
    "layer_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc3)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc3, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations, total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch, y_batch_cls = data.random_batch(batch_size=train_batch_size)\n",
    "\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  62.5%\n",
      "Optimization Iteration:    101, Training Accuracy:  65.6%\n",
      "Optimization Iteration:    201, Training Accuracy:  50.0%\n",
      "Optimization Iteration:    301, Training Accuracy:  68.8%\n",
      "Optimization Iteration:    401, Training Accuracy:  71.9%\n",
      "Optimization Iteration:    501, Training Accuracy:  59.4%\n",
      "Optimization Iteration:    601, Training Accuracy:  56.2%\n",
      "Optimization Iteration:    701, Training Accuracy:  75.0%\n",
      "Optimization Iteration:    801, Training Accuracy:  78.1%\n",
      "Optimization Iteration:    901, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   1001, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   1101, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   1201, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   1301, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   1401, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   1501, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   1601, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   1701, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   1801, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   1901, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   2001, Training Accuracy:  53.1%\n",
      "Optimization Iteration:   2101, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   2201, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   2301, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   2401, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   2501, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   2601, Training Accuracy:  56.2%\n",
      "Optimization Iteration:   2701, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   2801, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   2901, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   3001, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   3101, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   3201, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   3301, Training Accuracy:  56.2%\n",
      "Optimization Iteration:   3401, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   3501, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   3601, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   3701, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   3801, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   3901, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   4001, Training Accuracy:  53.1%\n",
      "Optimization Iteration:   4101, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   4201, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   4301, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   4401, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   4501, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   4601, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   4701, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   4801, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   4901, Training Accuracy:  50.0%\n",
      "Optimization Iteration:   5001, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   5101, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   5201, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   5301, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   5401, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   5501, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   5601, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   5701, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   5801, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   5901, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   6001, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   6101, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   6201, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   6301, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   6401, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   6501, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   6601, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   6701, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   6801, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   6901, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   7001, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   7101, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   7201, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   7301, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   7401, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   7501, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   7601, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   7701, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   7801, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   7901, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   8001, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   8101, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   8201, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   8301, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   8401, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   8501, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   8601, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   8701, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   8801, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   8901, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   9001, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   9101, Training Accuracy:  62.5%\n",
      "Optimization Iteration:   9201, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   9301, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   9401, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   9501, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   9601, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   9701, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   9801, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   9901, Training Accuracy:  75.0%\n",
      "Time usage: 0:00:06\n"
     ]
    }
   ],
   "source": [
    "#print(data.num_train)\n",
    "optimize(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy():\n",
    "    cls_pred = np.zeros(shape=data.num_test, dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < data.num_test:\n",
    "        j = min(i + test_batch_size, data.num_test)\n",
    "        \n",
    "        images = data.x_test_flat[i:j, :]\n",
    "        labels = data.y_test[i:j, :]\n",
    "\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        i = j\n",
    "\n",
    "    cls_true = data.y_test_cls\n",
    "    \n",
    "    correct = cls_true.transpose() == cls_pred\n",
    "    \n",
    "    correct_sum = correct.sum()\n",
    "    acc = float(correct_sum) / data.num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, data.num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 39.6% (118 / 298)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "\n",
    "x_val = []\n",
    "y_val_true = []\n",
    "for i in os.listdir('../data/letters/validation/'):\n",
    "    x_val.append(cv2.cvtColor(cv2.resize(cv2.imread('../data/letters/validation/' + i), data.img_shape), cv2.COLOR_BGR2GRAY).flatten())\n",
    "    y_val_true.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {x: np.vstack(x_val)}\n",
    "\n",
    "pred = session.run(y_pred_cls, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i == j for i, j in zip(y_val_true, [data.class_names[x] for x in pred])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
