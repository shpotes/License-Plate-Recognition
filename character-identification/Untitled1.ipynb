{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from util.dataset import DataSet\n",
    "from datetime import timedelta\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = DataSet(14, 0.85, '../data/letters/', validation=False)\n",
    "pickle.dump(data, open('../data/letters/dataset.pkl', 'wb' ))\n",
    "#data = pickle.load(open('../data/letters/dataset.pkl', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<util.dataset.DataSet at 0x7fd5d274a518>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i], cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(data.class_names[cls_true[i]])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(data.class_names[cls_true[i]], data.class_names[cls_pred[i]])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHZxJREFUeJzt3XuMVdXZx/Hv4j7AcEdA7sULoAilg1CIgBeaSmrV0lBt\njNpaUDHVN02sNiWWmrZWa9TUtPhWGi/Yat4ECtZIUVrBiiLQV0AceFG5yLVcHGQY7sx6/2DmdK+1\nNnMuc/acw8zvkzQ9z5m99lnMmv24z7PXXttYaxERaeqaFboDIiLFQMlQRAQlQxERQMlQRARQMhQR\nAZQMRUQAJUMREUDJUEQEUDIUEQGgRTYbG2Oa3O0q1lpT6D40pLZt29pOnTql4oMHDwbbHD161IlL\nSkqc+NSpU0GbkydPOnGHDh2c2Jjw1/zFF1+k73Aabdq0Cd770pe+lHq9a9cuKioqmtQY6ziOl1Uy\nlMavU6dOTJ8+PRUvXLgw2GbNmjVOPHjwYCfes2dP0Gb37t1OPG7cOCdu2bJl0ObVV19N3+E0Bg0a\nFLz3yiuvpF5/5zvfqfdnSOOgr8kiIigZiogAYLJZtaasrMyuXr06we7k1zvvvOPEV1xxRdb7aGo1\nw9atW9vevXun4tLS0mCbW2+91YlnzJjhxHE1wyNHjjhx27ZtndivOwLs2LHDieP64v/9rlixwoln\nzpwZtNm7d2/q9f79+zlx4kSTGuNMaoY33nijE8+fPz+x/qTz0EMPOfFrr73mxB988EHafWRyHOvM\nUEQEJUMREUDJUEQEUDIUEQEKcAGlV69ewXtx89KiRowYEbzXunVrJ/YL55kYPnx48N66deucuKld\nQBk5cqRdtmxZKm7fvn3aNseOHXPixYsXB9v4k7eHDh3qxJdeemnQxh9jf7I3QLt27Zz48OHDTrxy\n5cqgzU9+8pPU648++oiqqqomNcYlJSX2ggsuSMVxFyBatMh+CvKiRYuceOnSpWnbPProo1l/ji/u\ngt2Xv/zl1OtPPvmEo0eP6gKKiEgmlAxFRFAyFBEBGuDe5Lgb8LPl3wub6edMnDjRid966y0nXrt2\nbdBm2rRpqdcLFizIsIeNR7NmzZzJzZWVlcE2P/7xj5147ty5Tjxw4MCgzfr16+v83B/+8IfBe1VV\nVU585ZVXBtv4k4P9NtHaWK1orXjLli119qsxuuSSS8i29u8fg2PGjAm2OX78eNZ9eeyxx5w4OuG/\nlj/53hdX3/zwww9Tr8vKyjLqi84MRURQMhQRAZQMRUSABqgZ+ot4Hjp0KOmPlHrYsGEDo0ePTsV+\nDQ6gvLzciS+66CInPn36dNCmWTP3v7vNmzd34qeffjpt3+LmGd5www1O7C8i271796DNs88+m3qd\nyU3+4s7bS9LOnTuD9/z5iv61gHzRmaGICEqGIiKAkqGICKBkKCICNMAFlEJeMPEnWUt6R44ccRY3\niJvM7l+U8Ccud+3aNWjTr18/J7777rud2F/NGMJJvP5FGAgXavAfLBV3ASj6b6qurg5+LiH/WIqb\nAH+u05mhiAhKhiIigJKhiAjQADVD/wHjGzduzMt+P/vsMyfu27dv1vuILvJZa86cOTn3qTGKW3TV\nrwNHnzYHUFFREbTxF4B96qmnnDiTm/w3b94cvOcvTuzf1O8vIgEwderU1OsTJ06k/dzGpry8nJEj\nR6biuAVw/cUP/InOcYtCRxc5gdyOpfvvvz94L5dJ1t/61rdSrz/99NOM2ujMUEQEJUMREUDJUEQE\nKMADoRrSzJkznfiXv/xl1vtoag+Eat68uS0pKUnFd9xxR7BNdOFMgOXLlztxx44dgzb+HME777zT\niePmo/qLxD7yyCPBNn5t63e/+50T+/VMgG3btqVe//GPf2TXrl1NaoyNMWkP+mzyQqFlsoB0Jsex\nzgxFRFAyFBEBlAxFRAAlQxERoAEmXfs3dPur1sbp06ePE2/fvj1tm7Zt2wbvxa2MLHXr0aMH06dP\nT8VxK1D7k6r9J5rFLajgj6H/5MHPP/88aHPdddc5cdwE6QMHDjhx9OIPxF8AWrduXer1/Pnzg59L\nbk+17NmzpxPv3r07X91x5OOJm3F0ZigigpKhiAigZCgiAjRAzTAX/kTZffv2Bdv4C4weOXIk2Cap\n2kJjF/29xU2G9p94mOGkVyfetWuXE8ctCPvnP//Zib/44otgm/POO8+Jf/WrXznxsGHDgjaXXXZZ\n6rVfY5Tc+fXbXMQ9Hc+/hpAUnRmKiKBkKCICKBmKiABKhiIiQJFeQPEn18atVvLEE0+k3U9TeKJX\nvpWUlDBkyJBU3K1bt2Abf3JtdBIzxD9xzr/Isn//fieOuzhy8uTJoG8+f4Vsf1L/kiVLgjbLli1L\nvY6uYCNn16lTJyf++OOPg23i/lbS8Ves79+/f9b7yBedGYqIoGQoIgIoGYqIAA2w0nUuCzVkYt68\neU4cfRrW2fgLN8Qt7uBraitd+2P87rvvBts8+OCDTjx06FAnfu6554I2fh349ttvd+LS0tKgjb9I\nxOjRo4Ntxo0b58R+LblNmzZBm2id0Vrb5MY4k5Wuv/71rzvxokWL6v25cX8X3//+9+u930xopWsR\nkQwpGYqIoGQoIgIU6TzDTEyZMsWJM6l9+vPUojfs1/LnzDU11dXVTm110KBBwTb+Qq2VlZVOPGnS\npKDNhg0bnPj555934jFjxqTt26ZNm4L3zj//fCf2x/j3v/990Oapp56qc59Nzcsvvxy8d9NNN9V7\nv1dffbUT/+Mf/6j3PpOkM0MREZQMRUQAJUMREUDJUEQEOIcvoPj8ib8A5eXldbaZPHly8F5Tv4DS\nrFkz5yJE3CrW/oTpWbNmOfHhw4eDNps3b67zc1esWJG2b1VVVcF7/kIM/sT6xx9/PGgT/bvI5qaD\nxqJbt27ccMMNqTgfF0sgXAHdv7BW7HRmKCKCkqGICKBkKCICZLlQgzFmH9CUVsPsb63tnn6zxkNj\n3PhpjONllQxFRBorfU0WEUHJUEQESHieoTGmK/D3mrAncBrYVxNfbq09Eduwfp/ZAjgOfMiZf99m\n4BZr7aF8f5YUZoxrPncy8CTQHPhva+1vkvgcKegY/wi4oyZ8xlr7dF3b1/vzGqpmaIyZBRy21j7u\nvW9q+hE+Ui23z2kB7LfWdqqJ/wSss9Y+mo/9y9k14Bi3BP4PuBLYA6wGplhrtQRNwhpwjEcALwBj\ngFPAG8D3rbVb8rH/OAX5mmyMucAYU16TqD4C+hpjDkZ+fpMxZk7N6x7GmPnGmNXGmJXGmPRrPbne\nA3rnr/eSiYTHeAywwVq7zVp7HPgf4Pqk/i0SL+ExHgKssNYetdaeBN4Gbkzq3wKFrRkOBp601g4F\ndtax3W+Bx6y1ZcBUoPaXO9oY80xdH2CMaQ5cBbyany5LlpIa495AdFHFHeg/eIWS1Bh/CEwwxnQx\nxrQDrgX65rfrrkLem/yptTaTp0tdA1wcuUe2szGmxFr7PvD+WdqUGmPWAH0480t96yzbSbKSHGMp\nDomMsbV2vTHmCWAJcBj4gDO1ysQUMhlG77qvBqIrAkQfaWbIvkhbaa0dUfNflDeBO4FwyWNJWlJj\nvBP3LKEPdZ+VSHISO46ttX8A/gBgjHkM+KQe/UyrKKbW1BRdK4wxFxpjmuHWBpYA99QGNYXVTPdb\nBdwH3F/zlVkKJM9jvAIYaozpb4xpzZmvXSqFFFi+j2NjzHk1/z8A+CbwSj776yuKZFjjAWAx8C5n\nakC17gHGGWPWGWPKgWmQWc0QwFq7CtjImQNGCisvY1xTUL+XM2f95cBL1tr/S7rzkpF8HscLarZd\nANyV9PQ43Y4nIkJxnRmKiBSMkqGICEqGIiKAkqGICKBkKCICZDnp2hjTIJeeW7Vq5cTDhg3Ly37X\nr1/vxMePH0/bxlobPh6uEWuoMc6X7t271xmns2vXLioqKjTGWWrWLDyPatu2bdb78WezxD0BMR8y\nOY6L8lGhPXv2dOLVqzO52yfk/6IvvvhiJ/74449z2m9TF/f40KiGnK717W9/24nvuuuurNrffPPN\n+exOk9G+ffvgvZEjR2a9n5MnTzrx8uXLc+5TfelrsogIRXpmuG2b+6yauDMN/+wkk7ORuXPnOvGY\nMdmuBtb49ejRg9tuuy0Vx331eeihh5zYH4t0Z4751KNHDyfOtqRSUlKSz+6ck/yHvwNs37497TaF\nMnv2bCeeMWNGXvarM0MREZQMRUQAJUMREUDJUEQEyOECSrQ4nq8LGwcOHKizTSYF+Uy20QWT9Pr0\n6cOvf/3rVBz3e/XHp5ArH6X7e4vrW9wcuaakRYsWdO3aNRXv2bMn630cOhSuptW3b9+02/j8CzP+\nhZu4be6+++46Y4Bbbrkl9XrRokVp+wE6MxQRAZQMRUQAJUMRESCHmmG6+lC6n1dXh8+Y9t/LpP6X\nSZ3qhRdeSLuN1C1fdeGkpKsvN/X6YJwOHTpwzTXXZNXm+eefd+Lvfe97eemLX1fs2LFjsM2sWbOc\n+Gc/+1na/b700kup12VlZRn1RX8pIiIoGYqIAEqGIiJAAyzU4H/fj6sHNm9e9yONM6lbxfEXfJD0\nKisrWbZsWSqeMGFC2jYPP/ywE8fV6eJqxVIYAwcOdGpqmSjksZRLzTAXOjMUEUHJUEQEUDIUEQGU\nDEVEgAQWavD5xc5cLoacPn06eK9Fi6JcpPuct3//fubMmZOKM7mA4tPFEskn/wJKUnRmKCKCkqGI\nCKBkKCIC1HOhhs6dOwc///zzz8+6PUBFRUXQZsCAAU5cWVnpxOPHjw/aLF261Ikb8olsjdl5553H\nvffem4ozWdx16tSpTpxLjWfevHlpt4mrRU6ZMqXONrlO2G/MNm3axKRJk1Lxm2++mbaNX/v3xxxg\n+PDhTuw/EzlOy5YtnXjt2rXBNkOGDEm7H190cdctW7Zk1EZnhiIiKBmKiABKhiIiQD0XavAf5ATp\nF2qNPogmU2+//XbwXr4WgBVXu3btGDVqVCrO5Hfo13Tianu51OlyGb9MFp5t6n8XlZWVLFmyJBW3\natUq2Mav3fljHFfHO3HiRJ56WLcNGzY4sV+rhMzqlT6dGYqIoGQoIgIoGYqIAEqGIiIAmGyKyV27\ndrWTJ09OxS+++GKwjb8/f9XjVatWBW0uv/xyJ27durUTHz16NGiTSUE+3cWcuH97mzZtUq9PnTpF\ndXV1k5qhW1ZWZlevXl3nNumeSFdSUhK08SfX+gXuuPE8duxYnf2AcJXtmTNnOvGpU6eCNrfffnvq\n9aJFizhw4ECTGmNjTCJXkPwLql26dMnLfrdu3erEAwcOzHof1tq0Y6wzQxERlAxFRAAlQxERIMtJ\n1wMHDmTu3LlZfYBfX4pO6K2V1GKgcU9pi4qrU0UnjpaVleW9T43Rz3/+cyeOq/VlUv/LRVxNMCrd\nkxclN4MHDw7eKy0trfd+Z8yYEbw3e/bseu83EzozFBFByVBEBFAyFBEBlAxFRIAsL6CsXbuWXr16\npeK4lSvSTeLOZOXkn/70p0589dVXB23STaiOe89f7SKuWOuvoC3FzV8lPd2EcMmN/3v2j6VcFdP4\n6MxQRAQlQxERQMlQRATIsmZ46tQp9uzZk4qjr/PJr9vFTcpON6EawsnAuTy1TYpbdNGFOE19Vet8\nyfQJc3XJ5Sl3DUlnhiIiKBmKiABKhiIiQD2fjpeUbBeDgPja0NixY+tsk8mcRwn5v7dirsVmMv+0\nqUvqb37SpElOvHHjxkQ+J190ZigigpKhiAigZCgiAigZiogARXoBxV+o4bvf/W6wTSZPuvvkk0/q\n/BxdLIkX/b1kcrGhZ8+eTpzUZPy4ifbr1q1z4tOnTztxXP9feuml/HbsHNOlSxeuvfbaRPYbVVFR\nkffPSJLODEVEUDIUEQGUDEVEADDZ1M2MMfuAbcl1p+j0t9Z2L3QnGpLGuPHTGMfLKhmKiDRW+pos\nIoKSoYgIoGQoIgIkPOnaGNMV+HtN2BM4DeyriS+31p5I8LNbAP8LbLbW3pDU5zRlhRjfmnHdb63t\nFHnvB8Cl1tr/yvfnSeGOY2PMj4A7asJnrLVPJ/E5tRJNhtbaA8AIAGPMLOCwtfbx6DbmzC0Cxlob\nru1fPz8C1gNt87xfqVHg8ZUGUohxNsaMAG4DyoBTwBvGmNestfV//sBZFORrsjHmAmNMuTHmT8BH\nQF9jzMHIz28yxsyped3DGDPfGLPaGLPSGDMmg/33ByYBzyX1b5CzS3p8pTgkPM5DgBXW2qPW2pPA\n28CNSf1boLA1w8HAk9baocDOOrb7LfCYtbYMmArU/nJHG2OeOUubp4D7Ac0bKpwkx7fUGLOm9n/A\nQ/nsuGQlqXH+EJhgjOlijGkHXAv0zW/XXYVcqOFTa+3qDLa7Brg4csN9Z2NMibX2feB9f2NjzA3A\ndmvtGmPMNfnrrmQpkfGtUWmtHVEb1NYM69VbyVUi42ytXW+MeQJYAhwGPuBMrTIxhUyGVZHX1UB0\neZE2kdeG7Iq0Y4FvGWO+WbOfDsaYF6y1t9Wrt5KtpMZXikti42yt/QPwBwBjzGNA3ctQ1VNRTK2p\nKbpWGGMuNMY0w60NLAHuqQ1qCqt17evH1to+1toBwC3AG0qEhZXP8ZXile9xNsacV/P/A4BvAq/k\ns7++okiGNR4AFgPvAjsi798DjDPGrDPGlAPTIG1NSYqPxrdpyOc4L6jZdgFwl7X2UIL91r3JIiJQ\nXGeGIiIFo2QoIoKSoYgIoGQoIgJkOc+wW7dudsCAAQl1pfhs3bqV/fv3p388XCNijDmnr6h16tQp\n7TYHDx50Ymttkxpj/zj2nygIcPLkSSfesWOHEx89ejRoU11dnVUMmT19sWXLlk7cr18/J27fvn3Q\nJvokxW3btmV0HGeVDAcMGMCqVauyaZLRIz3TtYnTEFfBR40alfhnSH5deeWVabf5y1/+0gA9KV4D\nBgxg5cqVqfjw4cPBNjt3unfWPfjgg07sP6IVoKqqyon9hHns2LGgTfPmzZ047tjv0aOHEz/xxBNO\nPGHChKBN69atU6/Hjh0b/DyOviaLiKBkKCIC5HBvcvQ0NpOvqvn4Ohu3j2L5Ki2FVd8xLisry1NP\nzh3V1dXOV9q4Y+n111934qVLlzpx9GtoLf8rr//1O65Nun0AXHbZZU58/PhxJ477Gzhy5EjqdVyt\nMo7ODEVEUDIUEQGUDEVEACVDEREghwso0WJlXOH10CF3lZ1NmzY5sT+ZE6BNmzZO7BdIW7QIuxmd\nVAnxhVe/YOsXWv3JnH7/4uZFSXHx5xW+9dZbadtMmzYt9Xrbtm1571OxM8ZQUlKSirdsCZ+x9M9/\n/tOJe/Xq5cT+MXq2z4mKu5DhH7d9+vQJtomOF8D48eOduFWrVkGbysrK1OtML7LpzFBEBCVDERFA\nyVBEBKjnA6Hivov/7W9/c+L77rvPiffs2RO0idYvIP4mcJ9fR/RriBDWEvwaRlybaC0kk7qIFNaI\nEdk/MmXOnDkJ9OTcUV1d7UyIjvs7HzlypBPfeuutTrxixYqgzeLFi524b1/3yZ579+4N2nTo0MGJ\nL7zwwmAbf9K1f40hLg9Fj/1MbtAAnRmKiABKhiIigJKhiAiQwDxDf86SvybgX//616BNuhph3Oec\nOnWqzjYAJ07U/bzquIVANbfw3PLkk08WugvnpOhxHDff9rbb3EeNd+3a1Ym/8pWvBG2+8Y1vOLGf\nC/yaot8PgG7dup2lx//hz02MqxlGF3yNuzYQR2eGIiIoGYqIAEqGIiKAkqGICFDPla7j+BOo4xZZ\nSKe0tNSJ/ZvEISzOxi3U4F9A8W8U9xeVgOxX8hY51xw/ftxZoOLhhx8OtvEvZEycONGJBw0aFLS5\n5JJLnHjYsGFOfMUVVwRt2rVr58Rt27YNtvEnWfv8B1GBe9FEK12LiGRByVBEBCVDERGgngs1xPEX\nYvRv8J48eXLQ5o033nDijRs3OvH+/fuDNv4isXGLxvqTSf0aYP/+/YM20Rv/M1koVORcc/jwYZYt\nW5aKlyxZEmzj1+EWLFjgxEOGDAnaXH/99U7sL7wbt3BrdHI0xE8AP3DggBP7x3Hnzp2DNtHavyZd\ni4hkQclQRAQlQxERAEw2c+nKysrsqlWr/tM4g0UTM9m/v+iCX6+IWzxh4cKFTrx27dpgG39+Uffu\n3Z14+vTpdba57rrrWLduXWYrQzYSxphzanJlLnNB/b9ba22TGuOuXbvaaO1+3rx5wTb+MZfJwsh+\n/W/gwIFOPGbMmKDNlClTnLisrCzYxp9n6C/scvr06aBNdH7zxIkT+eCDD9KOsc4MRURQMhQRAZQM\nRUQAJUMRESCBp+P5ix/4RdW4wqs/0bJjx451xhB/8SOdTG7Yjk7ejpsA2tiVlJRw0UUXpeI1a9ak\nbeNPXv/ss8/y3i/Jn6qqKqIXQv2nSEK48Il/U0Pc4gn+sb9582Yn3r17d9DGfzJf3GRu/zj0Pzvu\nAms078Qt4hJHZ4YiIigZiogASoYiIkACCzXs3bvXif3FG+P4tUd/EuXq1auDNv7N5XETL3ft2uXE\n/mKvd955Z9Bm9OjRqdeZTCpvbIYOHRr7+67L+eef78SqGRa30tJSZ6HV9957L9hm69atTuwfo3HH\nRuvWrZ3YX+i5Q4cOQZvx48c7sf8UvjgVFRVp+xJ9Ly43xNGZoYgISoYiIoCSoYgIoGQoIgIkMOna\nv2jhP0Urro2/CsVrr73mxHErTr/88stOHPeku3TiJptGJxz7q+lIvBUrVhS6C5KF3r1788gjj6Ti\nd955J9imvLzcif/1r3858fLly4M2/oUK/8KGf6ENYOzYsU4cd6ODf+HTn0Qdd5F23759Z+3X2ejM\nUEQEJUMREUDJUEQEyKFmGK35xS18EJ20DGHd4MiRI0GbRx991In9m7dff/31oI2/n+jKtrX8WoFf\nr5wwYULQprS0NPU60xu8G5Nt27Y5Tzh89tlnC9gb1wMPPJB1m+HDhyfQk3Nbs2bNnDrbVVddFWzz\nta99zYkPHjzoxHFP1Is+cQ/C4++rX/1q0KZLly5OHFen//e//13nNnE1w06dOqVea6EGEZEsKBmK\niKBkKCIC5FAzjNYA/fmBENb7/MVc/e//AKNGjXLi2bNnO/H27dvT9itu0Vi/VuDXFfv16xe0iS5i\nmcuT18511tqM52VF2xSKX7duinXebFlrnb/zuN+Zfzz16tXLiW+++eagzY033ujE6RZ6hnBeYdw1\nBb9G6OeduDwU/bvI9O9TZ4YiIigZiogASoYiIoCSoYgIUM8LKHELHfhPrvKLlwsXLgza7Nmzx4nX\nr1+fbbdii8D+E738lXf9n4N7kaUprnR94MABnnvuuVQcfV3r+uuvd+Jf/OIXTnzppZfmpS+/+c1v\nnPjFF18Mtsnlb6WpO336tHNxI+7pk/7x5C+WEMe/QBK9gQHijzc/P8Rd7BgwYIAT+xdZ/Iu24PZX\nF1BERLKgZCgigpKhiAgAJpsJs8aYfcC25LpTdPpba7sXuhMNSWPc+GmM42WVDEVEGit9TRYRQclQ\nRASo5wOh0jHGdAX+XhP2BE4DtU9qudxam37yUvaf2QI4DnzImX/fZuAWa232T4ySjBVwrPdbazul\n3VhyUizjaoz5AXCptfa/8v15tRJNhtbaA8AIAGPMLOCwtfbx6DbmzMxmY60Nl83OXaW1tvZz/wTc\nDTxadxOpjwKOtSSoKY1rQb4mG2MuMMaU1ySqj4C+xpiDkZ/fZIyZU/O6hzFmvjFmtTFmpTFmTJYf\n9x7QO3+9l2w08FhLA2mM41rImuFg4Elr7VBgZx3b/RZ4zFpbBkwFan/Bo40xz9T1AcaY5sBVwKv5\n6bLkKPGxloJIclxLjTFrav8HPJTPjsdJ9GtyGp9aa1dnsN01wMWR+4Q7G2NKrLXvA++fpU1pzS+w\nD2dqh+FT6KUhJTnWUjhJjmuq1AX/qRnWq7dpFDIZVkVeVwPRVRGiqz0Ysi/UVlprRxhj2gFvAncC\nv8+5p1JfSY61FE6jGteimFpTU3itMMZcaIxpBkTXD18C3FMbGGNG+O3r2G8VcB9wf81XZimwpMZa\nCqsxjGtRJMMaDwCLgXeBHZH37wHGGWPWGWPKgWmQeR3JWrsK2MiZWoUUh3yNde00KikOiRzDDUW3\n48k5yxjzFeBpa+3YQvdFzn2FrBmK5MwYcw9nzjjuLXRfpHHQmaGICMVVMxQRKRglQxERlAxFRAAl\nQxERQMlQRARQMhQRAeD/AamuyKr7BjWwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5d5624710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(data.x_train[:9], data.y_train_cls[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, data.img_size_flat], name='x')\n",
    "y_true = tf.placeholder(tf.float32, [None, data.num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = lambda shape: tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "new_biases = lambda length: tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "    \n",
    "def new_fc_layer(inp, num_inputs, num_outputs, use_relu=True, keep_prob=0):\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    layer = inp\n",
    "    \n",
    "    if keep_prob:\n",
    "        layer = tf.nn.dropout(inp, keep_prob) * keep_prob\n",
    "\n",
    "    layer = tf.matmul(inp, weights) + biases\n",
    "\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_size = 128 \n",
    "fc2_size = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2 = new_fc_layer(inp=x, num_inputs=data.img_size_flat, num_outputs=fc2_size, use_relu=True, keep_prob=0.3)\n",
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 36) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc3 = new_fc_layer(inp=layer_fc2, num_inputs=fc2_size, num_outputs=data.num_classes)\n",
    "layer_fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc3)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc3, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations, total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch, y_batch_cls = data.random_batch(batch_size=train_batch_size)\n",
    "\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   7.8%\n",
      "Optimization Iteration:    101, Training Accuracy:  23.4%\n",
      "Optimization Iteration:    201, Training Accuracy:  21.9%\n",
      "Optimization Iteration:    301, Training Accuracy:  29.7%\n",
      "Optimization Iteration:    401, Training Accuracy:  53.1%\n",
      "Optimization Iteration:    501, Training Accuracy:  50.0%\n",
      "Optimization Iteration:    601, Training Accuracy:  64.1%\n",
      "Optimization Iteration:    701, Training Accuracy:  70.3%\n",
      "Optimization Iteration:    801, Training Accuracy:  68.8%\n",
      "Optimization Iteration:    901, Training Accuracy:  59.4%\n",
      "Optimization Iteration:   1001, Training Accuracy:  70.3%\n",
      "Optimization Iteration:   1101, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   1201, Training Accuracy:  71.9%\n",
      "Optimization Iteration:   1301, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   1401, Training Accuracy:  68.8%\n",
      "Optimization Iteration:   1501, Training Accuracy:  70.3%\n",
      "Optimization Iteration:   1601, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   1701, Training Accuracy:  73.4%\n",
      "Optimization Iteration:   1801, Training Accuracy:  82.8%\n",
      "Optimization Iteration:   1901, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   2001, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   2101, Training Accuracy:  65.6%\n",
      "Optimization Iteration:   2201, Training Accuracy:  70.3%\n",
      "Optimization Iteration:   2301, Training Accuracy:  78.1%\n",
      "Optimization Iteration:   2401, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   2501, Training Accuracy:  75.0%\n",
      "Optimization Iteration:   2601, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   2701, Training Accuracy:  85.9%\n",
      "Optimization Iteration:   2801, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   2901, Training Accuracy:  85.9%\n",
      "Optimization Iteration:   3001, Training Accuracy:  79.7%\n",
      "Optimization Iteration:   3101, Training Accuracy:  81.2%\n",
      "Optimization Iteration:   3201, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   3301, Training Accuracy:  82.8%\n",
      "Optimization Iteration:   3401, Training Accuracy:  84.4%\n",
      "Optimization Iteration:   3501, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   3601, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   3701, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   3801, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   3901, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   4001, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   4101, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   4201, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   4301, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   4401, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   4501, Training Accuracy:  79.7%\n",
      "Optimization Iteration:   4601, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   4701, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   4801, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   4901, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   5001, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   5101, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   5201, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   5301, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   5401, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   5501, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   5601, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   5701, Training Accuracy:  82.8%\n",
      "Optimization Iteration:   5801, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   5901, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   6001, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   6101, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   6201, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   6301, Training Accuracy:  85.9%\n",
      "Optimization Iteration:   6401, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   6501, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   6601, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   6701, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   6801, Training Accuracy:  85.9%\n",
      "Optimization Iteration:   6901, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   7001, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   7101, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   7201, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   7301, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   7401, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   7501, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   7601, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   7701, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   7801, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   7901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   8001, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   8101, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   8201, Training Accuracy:  85.9%\n",
      "Optimization Iteration:   8301, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   8401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   8501, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   8601, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   8701, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   8801, Training Accuracy:  89.1%\n",
      "Optimization Iteration:   8901, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   9001, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   9101, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   9201, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   9301, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   9401, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   9501, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   9601, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   9701, Training Accuracy:  87.5%\n",
      "Optimization Iteration:   9801, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   9901, Training Accuracy:  90.6%\n",
      "Time usage: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "#print(data.num_train)\n",
    "optimize(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "\n",
    "def print_test_accuracy():\n",
    "    cls_pred = np.zeros(shape=data.num_test, dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < data.num_test:\n",
    "        j = min(i + test_batch_size, data.num_test)\n",
    "        \n",
    "        images = data.x_test_flat[i:j, :]\n",
    "        labels = data.y_test[i:j, :]\n",
    "\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        i = j\n",
    "\n",
    "    cls_true = data.y_test_cls\n",
    "    \n",
    "    correct = cls_true.transpose() == cls_pred\n",
    "    \n",
    "    correct_sum = correct.sum()\n",
    "    acc = float(correct_sum) / data.num_test\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, data.num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 46.9% (84 / 179)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
